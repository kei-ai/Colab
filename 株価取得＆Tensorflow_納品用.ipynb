{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "株価取得＆Tensorflow_納品用",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1P7J2jw0E_VQr5cg40DGt9QzLnkjTMYYb",
      "authorship_tag": "ABX9TyPAHGA8TzfOAB0gO+zRr28a",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kei-ai/Colab/blob/main/%E6%A0%AA%E4%BE%A1%E5%8F%96%E5%BE%97%EF%BC%86Tensorflow_%E7%B4%8D%E5%93%81%E7%94%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-qyaUMzWYZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d46591eb-bf39-424c-cdee-359aa5f20add"
      },
      "source": [
        "!pip install yahoo_finance_api2\n",
        "import sys\n",
        "import csv\n",
        "import os\n",
        "from yahoo_finance_api2 import share\n",
        "from yahoo_finance_api2.exceptions import YahooFinanceError\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install pandas\n",
        "import numpy as np \n",
        "np.random.seed(202)\n",
        "import pandas as pd \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "import os.path\n",
        "from keras.models import model_from_json\n",
        "\n",
        "!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/libta-lib0_0.4.0-oneiric1_amd64.deb -qO libta.deb\n",
        "!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/ta-lib0-dev_0.4.0-oneiric1_amd64.deb -qO ta.deb\n",
        "!dpkg -i libta.deb ta.deb\n",
        "!pip install ta-lib\n",
        "import talib\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yahoo_finance_api2\n",
            "  Downloading https://files.pythonhosted.org/packages/e0/41/4fb0a68f954027fae3454631f0d6cf457cbc2877f8d50dc1bc21b01acbf3/yahoo_finance_api2-0.0.9.tar.gz\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from yahoo_finance_api2) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from yahoo_finance_api2) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->yahoo_finance_api2) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->yahoo_finance_api2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->yahoo_finance_api2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->yahoo_finance_api2) (1.24.3)\n",
            "Building wheels for collected packages: yahoo-finance-api2\n",
            "  Building wheel for yahoo-finance-api2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yahoo-finance-api2: filename=yahoo_finance_api2-0.0.9-cp36-none-any.whl size=3690 sha256=ece10fa47d8de4b3c40a0f6100ae4bb732e1cdf726e0fa668f085210af1325bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/39/5b/85c9dfaaf940699ca6dadd79685eff20828edc4890197f552a\n",
            "Successfully built yahoo-finance-api2\n",
            "Installing collected packages: yahoo-finance-api2\n",
            "Successfully installed yahoo-finance-api2-0.0.9\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.11.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Selecting previously unselected package libta-lib0.\n",
            "(Reading database ... 144793 files and directories currently installed.)\n",
            "Preparing to unpack libta.deb ...\n",
            "Unpacking libta-lib0 (0.4.0-oneiric1) ...\n",
            "Selecting previously unselected package ta-lib0-dev.\n",
            "Preparing to unpack ta.deb ...\n",
            "Unpacking ta-lib0-dev (0.4.0-oneiric1) ...\n",
            "Setting up libta-lib0 (0.4.0-oneiric1) ...\n",
            "Setting up ta-lib0-dev (0.4.0-oneiric1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting ta-lib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/cf/681911aa31e04ba171ab4d523a412f4a746e30d3eacb1738799d181e028b/TA-Lib-0.4.19.tar.gz (267kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta-lib) (1.18.5)\n",
            "Building wheels for collected packages: ta-lib\n",
            "  Building wheel for ta-lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta-lib: filename=TA_Lib-0.4.19-cp36-cp36m-linux_x86_64.whl size=1437802 sha256=9cc99cff9ade671cab028cdc0f013b0e07eaaef00ae2146ff7fcb012bb80a373\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/f6/12/3d1ccd06caadd8fa47e016991dd0d27f1163bb260f1854e2ff\n",
            "Successfully built ta-lib\n",
            "Installing collected packages: ta-lib\n",
            "Successfully installed ta-lib-0.4.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUhKDl_5WXSx",
        "outputId": "77e3bd0d-a6fd-4106-c94f-a1ef6ed7c838"
      },
      "source": [
        "\n",
        "def get_D1():\n",
        "    global df\n",
        "    global d\n",
        "    my_share = share.Share(code + '.T')\n",
        "    symbol_data = None\n",
        "\n",
        "    try:\n",
        "        symbol_data = my_share.get_historical(share.PERIOD_TYPE_YEAR, 20,\n",
        "                                             share.FREQUENCY_TYPE_DAY, 1)\n",
        "        time.sleep(2)\n",
        "    except YahooFinanceError as e:\n",
        "        print(e.message)\n",
        "        sys.exit(1)\n",
        "\n",
        "  #------------------------------------------\n",
        "    #Dataframe\n",
        "    df = pd.DataFrame(symbol_data)\n",
        "    def convert_timestamp_to_date(timestamp):\n",
        "        return dt.datetime.fromtimestamp(timestamp/1000.0).isoformat()\n",
        "    lst = list(map(convert_timestamp_to_date, df['timestamp']))\n",
        "    df.insert(1, 'date',lst)\n",
        "    df['date'] = pd.to_datetime(df['date'])+datetime.timedelta(hours=9)\n",
        "    df.drop(columns=['timestamp'], axis=1,inplace=True)#inplaceで上書き\n",
        "   \n",
        "    #df.drop(columns=['high'], axis=1,inplace=True)#inplaceで上書き\n",
        "    #df.drop(columns=['low'], axis=1,inplace=True)#inplaceで上書き\n",
        "    #df.drop(columns=['open'], axis=1,inplace=True)#inplaceで上書き\n",
        "    df['volume']=df['volume']+1\n",
        "    #0だとエラーのなるので+1\n",
        "\n",
        "    df=df.dropna(how='any')\n",
        "    d=df\n",
        "    d.drop(columns=['high'], axis=1,inplace=True)\n",
        "    d.drop(columns=['low'], axis=1,inplace=True)\n",
        "    d.drop(columns=['open'], axis=1,inplace=True)\n",
        "    d.drop(columns=['volume'], axis=1,inplace=True)\n",
        "    \n",
        "\n",
        "    df=tec(df).dropna(how='any')\n",
        "    print(df)\n",
        "    df=df.set_index('date')  \n",
        "loss=\"mae\"\n",
        "optimizer=\"adam\"\n",
        "activ_func=\"linear\"\n",
        "output_size=1\n",
        "\n",
        "dropout=0.01\n",
        "neurons=100\n",
        "\n",
        "f_log = '/content/drive/My Drive/Price/LSTM/log'\n",
        "f_model = '/content/drive/My Drive/Price/LSTM/model'\n",
        "os.makedirs('/content/drive/My Drive/Price/LSTM', exist_ok=True)\n",
        "#使うインジケータ\n",
        "def tec(X):\n",
        "    close = np.array(X['close'])\n",
        "    output = close.copy()\n",
        "    cols = ['Original']\n",
        "\n",
        "\n",
        "    # 単純移動平均(SMA: Simple Moving Average)\n",
        "    output = np.c_[output, talib.SMA(close,timeperiod=21)]\n",
        "    cols += ['SMA']\n",
        "\n",
        "\n",
        "    # 指数移動平均(EMA: Exponential Moving Average)\n",
        "    output = np.c_[output, talib.EMA(close,timeperiod=21)]\n",
        "    cols += ['EMA']\n",
        "\n",
        "\n",
        "    # ボリンジャー・バンド(Bollinger Bands)\n",
        "    for arr in talib.BBANDS(close, timeperiod=15, nbdevup=2, nbdevdn=2, matype=0):\n",
        "        output = np.c_[output, arr]\n",
        "    cols += ['BB_up', 'BB_middle', 'BB_low']\n",
        "\n",
        "\n",
        "    #RSI: Relative Strength Index\n",
        "    output = np.c_[output, talib.RSI(close,timeperiod=21)]\n",
        "    cols += ['RSI']\n",
        "\n",
        "\n",
        "    # MACD: Moving Average Convergence/Divergence\n",
        "    for arr in talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9):\n",
        "        output = np.c_[output, arr]\n",
        "    cols += ['MACD', 'MACD_signal', 'MACD_hist']\n",
        "\n",
        "\n",
        "    data = pd.DataFrame(output, index=X.index, columns=cols)\n",
        "    data=pd.concat([X,data],axis=1)\n",
        "    data=data.drop(['Original'],axis=1)\n",
        "    return data\n",
        "\n",
        "#==============================================================================\n",
        "def input():\n",
        "    #①テンソル化\n",
        "    global train_lstm_in\n",
        "    global test_lstm_in\n",
        "    global X_train\n",
        "    global X_test\n",
        "    global Loss\n",
        "    get_D1()\n",
        "    #パラメータ\n",
        "\n",
        "    X_data = df\n",
        "    test_idx_from = int(len(df)*3/4) #学習させるデータ数\n",
        "    #学習用データ\n",
        "    X_train = X_data\n",
        "\n",
        "    #テスト用データ\n",
        "    X_test  = X_data[-window_len-1:]\n",
        "\n",
        "    train_lstm_in = []\n",
        "    for i in range(len(X_train) - window_len):\n",
        "        temp = X_train[i:(i + window_len)].copy()\n",
        "        temp.iloc[:, :] = temp.iloc[:,:]  / temp.iloc[0, :] - 1\n",
        "        train_lstm_in.append(temp)\n",
        "\n",
        "    test_lstm_in = []\n",
        "    for i in range(len(X_test) - window_len):\n",
        "        temp = X_test[i:(i + window_len)].copy()\n",
        "        temp.iloc[:, :] = temp.iloc[:, :]  / temp.iloc[0,:] - 1\n",
        "        test_lstm_in.append(temp)\n",
        "\n",
        "    train_lstm_in = [np.array(train_lstm_input) for train_lstm_input in train_lstm_in]\n",
        "    train_lstm_in = np.array(train_lstm_in)\n",
        "    \n",
        "    test_lstm_in = [np.array(test_lstm_input) for test_lstm_input in test_lstm_in]\n",
        "    test_lstm_in = np.array(test_lstm_in)\n",
        "\n",
        "def output(): #上がるか下がるか\n",
        "    global lstm_train_out\n",
        "    global lstm_test_out\n",
        "\n",
        "    up_down=X_train['close'][window_len:].values-X_train['close'][window_len-n:-n].values\n",
        "    lstm_train_out = np.zeros_like(up_down)#価格が下がれば０\n",
        "    lstm_train_out[up_down > 0] = 1 \n",
        "\n",
        "    up_down=X_test['close'][window_len:].values-X_test['close'][window_len-n:-n].values\n",
        "    lstm_test_out = np.zeros_like(up_down)#価格が下がれば０\n",
        "    lstm_test_out[up_down > 0] = 1 \n",
        "                  #上昇トレンドなら１、下降トレンドなら0\n",
        "\n",
        "def output2(): #変動\n",
        "    global lstm_train_out\n",
        "    global lstm_test_out\n",
        "\n",
        "\n",
        "    up_down=X_train['close'][window_len:].values-X_train['close'][window_len-n:-n].values\n",
        "    lstm_train_out = up_down/X_train['close'][window_len:].values\n",
        "\n",
        "\n",
        "    up_down=X_test['close'][window_len:].values-X_test['close'][window_len-n:-n].values\n",
        "    lstm_test_out = up_down/X_test['close'][window_len:].values\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    global model\n",
        "    global MAE\n",
        "    global score\n",
        "    #②学習スタート\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(LSTM(neurons))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(units=output_size))\n",
        "    model.add(Activation(activ_func))\n",
        " \n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "    model.fit(train_lstm_in, lstm_train_out, \n",
        "                            epochs= epoch, batch_size=1, verbose=2, shuffle=None)\n",
        "\n",
        "    score = model.evaluate(test_lstm_in, lstm_test_out, verbose=0)\n",
        "    MAE=score[0]\n",
        "    print('Test score:', MAE)\n",
        "    print('正答率:', score[1])\n",
        "   \n",
        "   \n",
        "   \n",
        "    #③学習モデル保存\n",
        "    model_filename = '/cnn_mode_'+str(window_len)+'.json'\n",
        "    model_yaml='/cnn_model_'+str(window_len)+'.yaml'\n",
        "    weights_filename = '/cnn_model_weights_'+str(window_len)+'.hdf5'\n",
        "                      #モデルファイル名\n",
        "\n",
        "    print('save the architecture of a model')\n",
        "    json_string = model.to_json()\n",
        "    open(os.path.join(f_model,model_filename), 'w').write(json_string)\n",
        "    yaml_string = model.to_yaml()\n",
        "    open(os.path.join(f_model,), 'w').write(yaml_string)\n",
        "    print('save weights')\n",
        "    model.save_weights(os.path.join(f_model,weights_filename))\n",
        "    #model.summary()\n",
        "\n",
        "\n",
        "def predict(n):\n",
        "    global df2,df4\n",
        "    global v\n",
        "    global p\n",
        "    global pp\n",
        "    output2()\n",
        "    build_model()\n",
        "    #use_saved_model(window_len,epoch)\n",
        "\n",
        "    predict = []\n",
        "    for i in range(1,window_len):\n",
        "            temp = X_test[-i-window_len:-i].copy()\n",
        "            temp.iloc[:, :] = temp.iloc[:, :]  / temp.iloc[0, :] - 1\n",
        "            predict.append(temp)\n",
        "\n",
        "    predict = [np.array(train_lstm_input) for train_lstm_input in predict]\n",
        "    predict = np.array(train_lstm_in)\n",
        "    #print('過去',window_len,'日間のデータをもとに予測した',n,'日後の変動率は',model.predict(predict)[-n-1:-1]*100,'%です。')\n",
        "    v=model.predict(predict)\n",
        "    df2 = pd.DataFrame(v[-n-1:-1])\n",
        "    df2.insert(1,'close',df2)\n",
        "    df2.drop(columns=[0], axis=1,inplace=True)\n",
        "    df4=pd.concat([df3,df2],axis=0)\n",
        "    f=df4[-2*n:-n]\n",
        "    for i in range(0,n):\n",
        "      df4.iloc[-n+i, :] = f.iloc[-n+i, :]  *(1+ df4.iloc[-n+i, :] )\n",
        "      df4=df4.rename(index={i: 1001+i})\n",
        "    #df2= df2.rename(index={0: n})\n",
        "\n",
        "    #Loss= pd.DataFrame({code: [MAE]},\n",
        "                  #index=[k+10])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " #過去X日間から  \n",
        "            #n日後の上下を予想\n",
        "epoch=20\n",
        "count = 1\n",
        "error=0\n",
        "\n",
        "csvfile = \"/content/drive/My Drive/Price/銘柄2.csv\"\n",
        "with open(csvfile, \"r\") as f:\n",
        "    total = csv.reader(f)\n",
        "    for number in total:\n",
        "        \n",
        "        code = str(\"\".join(number))\n",
        "        print(\"ループ回数: \" + str(count))\n",
        "        print(code)\n",
        "        count=count+1\n",
        "        df6=pd.DataFrame()\n",
        "        try:    \n",
        "            for m in range(1,4):\n",
        "              window_len=20*m\n",
        "              input()\n",
        "              df4=pd.DataFrame()\n",
        "              df5=pd.DataFrame()\n",
        "              \n",
        "              df3= d[-20-1:-1]\n",
        "              df3.drop(columns=['date'], axis=1,inplace=True)\n",
        "              for n in range(1,6):\n",
        "                predict(n)\n",
        "                df5=pd.concat([df5,df4],axis=1)\n",
        "              df6=pd.concat([df6,df5],axis=1)\n",
        "            \n",
        "            df6.to_csv(\"/content/drive/My Drive/Price/DL_\"+code+\".csv\")\n",
        "        except:\n",
        "            print(\"Error\")\n",
        "            error=error+1\n",
        "            print(\"Error回数: \" + str(error))\n",
        "            pass\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ループ回数: 1\n",
            "3994\n",
            "                   date   close          SMA  ...       MACD  MACD_signal  MACD_hist\n",
            "33  2017-11-15 09:00:00  1477.5  1514.023810  ...  -5.884713    -5.267630  -0.617083\n",
            "34  2017-11-16 09:00:00  1489.0  1513.833333  ...  -7.104850    -5.635074  -1.469776\n",
            "35  2017-11-17 09:00:00  1522.5  1516.666667  ...  -5.307466    -5.569552   0.262086\n",
            "36  2017-11-20 09:00:00  1527.5  1517.619048  ...  -3.439916    -5.143625   1.703709\n",
            "37  2017-11-21 09:00:00  1525.0  1519.095238  ...  -2.136964    -4.542293   2.405329\n",
            "..                  ...     ...          ...  ...        ...          ...        ...\n",
            "787 2020-11-30 09:00:00  4720.0  4686.666667  ...  11.473962    50.075913 -38.601951\n",
            "788 2020-12-01 09:00:00  4865.0  4693.571429  ...  32.220030    46.504737 -14.284707\n",
            "789 2020-12-02 09:00:00  4800.0  4697.619048  ...  42.921706    45.788131  -2.866424\n",
            "790 2020-12-03 09:00:00  4835.0  4717.380952  ...  53.609097    47.352324   6.256774\n",
            "791 2020-12-04 11:35:01  4665.0  4715.000000  ...  47.810226    47.443904   0.366322\n",
            "\n",
            "[759 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "739/739 - 4s - loss: 0.1480 - accuracy: 0.0501\n",
            "Epoch 2/20\n",
            "739/739 - 4s - loss: 0.0860 - accuracy: 0.0474\n",
            "Epoch 3/20\n",
            "739/739 - 4s - loss: 0.0586 - accuracy: 0.0501\n",
            "Epoch 4/20\n",
            "739/739 - 4s - loss: 0.0492 - accuracy: 0.0501\n",
            "Epoch 5/20\n",
            "739/739 - 4s - loss: 0.0445 - accuracy: 0.0501\n",
            "Epoch 6/20\n",
            "739/739 - 4s - loss: 0.0426 - accuracy: 0.0501\n",
            "Epoch 7/20\n",
            "739/739 - 4s - loss: 0.0348 - accuracy: 0.0501\n",
            "Epoch 8/20\n",
            "739/739 - 4s - loss: 0.0342 - accuracy: 0.0501\n",
            "Epoch 9/20\n",
            "739/739 - 4s - loss: 0.0333 - accuracy: 0.0501\n",
            "Epoch 10/20\n",
            "739/739 - 4s - loss: 0.0323 - accuracy: 0.0501\n",
            "Epoch 11/20\n",
            "739/739 - 4s - loss: 0.0302 - accuracy: 0.0501\n",
            "Epoch 12/20\n",
            "739/739 - 4s - loss: 0.0296 - accuracy: 0.0501\n",
            "Epoch 13/20\n",
            "739/739 - 4s - loss: 0.0288 - accuracy: 0.0501\n",
            "Epoch 14/20\n",
            "739/739 - 4s - loss: 0.0292 - accuracy: 0.0501\n",
            "Epoch 15/20\n",
            "739/739 - 4s - loss: 0.0289 - accuracy: 0.0501\n",
            "Epoch 16/20\n",
            "739/739 - 4s - loss: 0.0290 - accuracy: 0.0501\n",
            "Epoch 17/20\n",
            "739/739 - 4s - loss: 0.0283 - accuracy: 0.0501\n",
            "Epoch 18/20\n",
            "739/739 - 4s - loss: 0.0281 - accuracy: 0.0501\n",
            "Epoch 19/20\n",
            "739/739 - 4s - loss: 0.0285 - accuracy: 0.0501\n",
            "Epoch 20/20\n",
            "739/739 - 4s - loss: 0.0277 - accuracy: 0.0501\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57af22ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.034370288252830505\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "739/739 - 3s - loss: 0.1338 - accuracy: 0.0162\n",
            "Epoch 2/20\n",
            "739/739 - 4s - loss: 0.0987 - accuracy: 0.0176\n",
            "Epoch 3/20\n",
            "739/739 - 4s - loss: 0.0720 - accuracy: 0.0176\n",
            "Epoch 4/20\n",
            "739/739 - 4s - loss: 0.0624 - accuracy: 0.0176\n",
            "Epoch 5/20\n",
            "739/739 - 4s - loss: 0.0528 - accuracy: 0.0176\n",
            "Epoch 6/20\n",
            "739/739 - 4s - loss: 0.0464 - accuracy: 0.0176\n",
            "Epoch 7/20\n",
            "739/739 - 4s - loss: 0.0457 - accuracy: 0.0176\n",
            "Epoch 8/20\n",
            "739/739 - 4s - loss: 0.0429 - accuracy: 0.0176\n",
            "Epoch 9/20\n",
            "739/739 - 4s - loss: 0.0398 - accuracy: 0.0176\n",
            "Epoch 10/20\n",
            "739/739 - 4s - loss: 0.0401 - accuracy: 0.0176\n",
            "Epoch 11/20\n",
            "739/739 - 4s - loss: 0.0375 - accuracy: 0.0176\n",
            "Epoch 12/20\n",
            "739/739 - 4s - loss: 0.0352 - accuracy: 0.0176\n",
            "Epoch 13/20\n",
            "739/739 - 4s - loss: 0.0359 - accuracy: 0.0176\n",
            "Epoch 14/20\n",
            "739/739 - 4s - loss: 0.0349 - accuracy: 0.0176\n",
            "Epoch 15/20\n",
            "739/739 - 4s - loss: 0.0338 - accuracy: 0.0176\n",
            "Epoch 16/20\n",
            "739/739 - 4s - loss: 0.0330 - accuracy: 0.0176\n",
            "Epoch 17/20\n",
            "739/739 - 4s - loss: 0.0338 - accuracy: 0.0176\n",
            "Epoch 18/20\n",
            "739/739 - 4s - loss: 0.0325 - accuracy: 0.0176\n",
            "Epoch 19/20\n",
            "739/739 - 4s - loss: 0.0328 - accuracy: 0.0176\n",
            "Epoch 20/20\n",
            "739/739 - 4s - loss: 0.0321 - accuracy: 0.0176\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57a767c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.03428100049495697\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "739/739 - 4s - loss: 0.1670 - accuracy: 0.0122\n",
            "Epoch 2/20\n",
            "739/739 - 4s - loss: 0.1018 - accuracy: 0.0122\n",
            "Epoch 3/20\n",
            "739/739 - 4s - loss: 0.0753 - accuracy: 0.0122\n",
            "Epoch 4/20\n",
            "739/739 - 4s - loss: 0.0634 - accuracy: 0.0122\n",
            "Epoch 5/20\n",
            "739/739 - 4s - loss: 0.0588 - accuracy: 0.0122\n",
            "Epoch 6/20\n",
            "739/739 - 4s - loss: 0.0547 - accuracy: 0.0122\n",
            "Epoch 7/20\n",
            "739/739 - 4s - loss: 0.0509 - accuracy: 0.0122\n",
            "Epoch 8/20\n",
            "739/739 - 4s - loss: 0.0513 - accuracy: 0.0122\n",
            "Epoch 9/20\n",
            "739/739 - 4s - loss: 0.0458 - accuracy: 0.0122\n",
            "Epoch 10/20\n",
            "739/739 - 4s - loss: 0.0430 - accuracy: 0.0122\n",
            "Epoch 11/20\n",
            "739/739 - 4s - loss: 0.0422 - accuracy: 0.0122\n",
            "Epoch 12/20\n",
            "739/739 - 4s - loss: 0.0409 - accuracy: 0.0122\n",
            "Epoch 13/20\n",
            "739/739 - 4s - loss: 0.0393 - accuracy: 0.0122\n",
            "Epoch 14/20\n",
            "739/739 - 4s - loss: 0.0388 - accuracy: 0.0122\n",
            "Epoch 15/20\n",
            "739/739 - 4s - loss: 0.0382 - accuracy: 0.0122\n",
            "Epoch 16/20\n",
            "739/739 - 4s - loss: 0.0353 - accuracy: 0.0122\n",
            "Epoch 17/20\n",
            "739/739 - 4s - loss: 0.0376 - accuracy: 0.0122\n",
            "Epoch 18/20\n",
            "739/739 - 4s - loss: 0.0356 - accuracy: 0.0122\n",
            "Epoch 19/20\n",
            "739/739 - 4s - loss: 0.0365 - accuracy: 0.0122\n",
            "Epoch 20/20\n",
            "739/739 - 4s - loss: 0.0343 - accuracy: 0.0122\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57a4eddb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.03282211720943451\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "739/739 - 4s - loss: 0.1678 - accuracy: 0.0054\n",
            "Epoch 2/20\n",
            "739/739 - 4s - loss: 0.0967 - accuracy: 0.0054\n",
            "Epoch 3/20\n",
            "739/739 - 4s - loss: 0.0739 - accuracy: 0.0054\n",
            "Epoch 4/20\n",
            "739/739 - 4s - loss: 0.0665 - accuracy: 0.0054\n",
            "Epoch 5/20\n",
            "739/739 - 4s - loss: 0.0626 - accuracy: 0.0054\n",
            "Epoch 6/20\n",
            "739/739 - 4s - loss: 0.0541 - accuracy: 0.0054\n",
            "Epoch 7/20\n",
            "739/739 - 4s - loss: 0.0499 - accuracy: 0.0054\n",
            "Epoch 8/20\n",
            "739/739 - 4s - loss: 0.0465 - accuracy: 0.0054\n",
            "Epoch 9/20\n",
            "739/739 - 3s - loss: 0.0463 - accuracy: 0.0054\n",
            "Epoch 10/20\n",
            "739/739 - 4s - loss: 0.0460 - accuracy: 0.0054\n",
            "Epoch 11/20\n",
            "739/739 - 4s - loss: 0.0434 - accuracy: 0.0054\n",
            "Epoch 12/20\n",
            "739/739 - 4s - loss: 0.0431 - accuracy: 0.0054\n",
            "Epoch 13/20\n",
            "739/739 - 4s - loss: 0.0420 - accuracy: 0.0054\n",
            "Epoch 14/20\n",
            "739/739 - 4s - loss: 0.0417 - accuracy: 0.0054\n",
            "Epoch 15/20\n",
            "739/739 - 4s - loss: 0.0391 - accuracy: 0.0054\n",
            "Epoch 16/20\n",
            "739/739 - 4s - loss: 0.0385 - accuracy: 0.0054\n",
            "Epoch 17/20\n",
            "739/739 - 4s - loss: 0.0375 - accuracy: 0.0054\n",
            "Epoch 18/20\n",
            "739/739 - 4s - loss: 0.0367 - accuracy: 0.0054\n",
            "Epoch 19/20\n",
            "739/739 - 4s - loss: 0.0375 - accuracy: 0.0054\n",
            "Epoch 20/20\n",
            "739/739 - 4s - loss: 0.0374 - accuracy: 0.0054\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57b5f58268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.01511097326874733\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "739/739 - 4s - loss: 0.1643 - accuracy: 0.0014\n",
            "Epoch 2/20\n",
            "739/739 - 4s - loss: 0.0939 - accuracy: 0.0014\n",
            "Epoch 3/20\n",
            "739/739 - 4s - loss: 0.0789 - accuracy: 0.0014\n",
            "Epoch 4/20\n",
            "739/739 - 4s - loss: 0.0706 - accuracy: 0.0014\n",
            "Epoch 5/20\n",
            "739/739 - 4s - loss: 0.0644 - accuracy: 0.0014\n",
            "Epoch 6/20\n",
            "739/739 - 4s - loss: 0.0610 - accuracy: 0.0014\n",
            "Epoch 7/20\n",
            "739/739 - 4s - loss: 0.0562 - accuracy: 0.0014\n",
            "Epoch 8/20\n",
            "739/739 - 4s - loss: 0.0538 - accuracy: 0.0014\n",
            "Epoch 9/20\n",
            "739/739 - 4s - loss: 0.0505 - accuracy: 0.0014\n",
            "Epoch 10/20\n",
            "739/739 - 4s - loss: 0.0471 - accuracy: 0.0014\n",
            "Epoch 11/20\n",
            "739/739 - 4s - loss: 0.0454 - accuracy: 0.0014\n",
            "Epoch 12/20\n",
            "739/739 - 4s - loss: 0.0445 - accuracy: 0.0014\n",
            "Epoch 13/20\n",
            "739/739 - 4s - loss: 0.0430 - accuracy: 0.0014\n",
            "Epoch 14/20\n",
            "739/739 - 4s - loss: 0.0439 - accuracy: 0.0014\n",
            "Epoch 15/20\n",
            "739/739 - 4s - loss: 0.0407 - accuracy: 0.0014\n",
            "Epoch 16/20\n",
            "739/739 - 4s - loss: 0.0409 - accuracy: 0.0014\n",
            "Epoch 17/20\n",
            "739/739 - 4s - loss: 0.0414 - accuracy: 0.0014\n",
            "Epoch 18/20\n",
            "739/739 - 4s - loss: 0.0401 - accuracy: 0.0014\n",
            "Epoch 19/20\n",
            "739/739 - 4s - loss: 0.0391 - accuracy: 0.0014\n",
            "Epoch 20/20\n",
            "739/739 - 4s - loss: 0.0390 - accuracy: 0.0014\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57c40caea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.019850030541419983\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "                   date   close          SMA  ...       MACD  MACD_signal  MACD_hist\n",
            "33  2017-11-15 09:00:00  1477.5  1514.023810  ...  -5.884713    -5.267630  -0.617083\n",
            "34  2017-11-16 09:00:00  1489.0  1513.833333  ...  -7.104850    -5.635074  -1.469776\n",
            "35  2017-11-17 09:00:00  1522.5  1516.666667  ...  -5.307466    -5.569552   0.262086\n",
            "36  2017-11-20 09:00:00  1527.5  1517.619048  ...  -3.439916    -5.143625   1.703709\n",
            "37  2017-11-21 09:00:00  1525.0  1519.095238  ...  -2.136964    -4.542293   2.405329\n",
            "..                  ...     ...          ...  ...        ...          ...        ...\n",
            "787 2020-11-30 09:00:00  4720.0  4686.666667  ...  11.473962    50.075913 -38.601951\n",
            "788 2020-12-01 09:00:00  4865.0  4693.571429  ...  32.220030    46.504737 -14.284707\n",
            "789 2020-12-02 09:00:00  4800.0  4697.619048  ...  42.921706    45.788131  -2.866424\n",
            "790 2020-12-03 09:00:00  4835.0  4717.380952  ...  53.609097    47.352324   6.256774\n",
            "791 2020-12-04 12:31:29  4640.0  4713.809524  ...  45.815924    47.045044  -1.229120\n",
            "\n",
            "[759 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "719/719 - 7s - loss: 0.1527 - accuracy: 0.0417\n",
            "Epoch 2/20\n",
            "719/719 - 7s - loss: 0.1019 - accuracy: 0.0417\n",
            "Epoch 3/20\n",
            "719/719 - 7s - loss: 0.0770 - accuracy: 0.0417\n",
            "Epoch 4/20\n",
            "719/719 - 7s - loss: 0.0582 - accuracy: 0.0417\n",
            "Epoch 5/20\n",
            "719/719 - 7s - loss: 0.0527 - accuracy: 0.0417\n",
            "Epoch 6/20\n",
            "719/719 - 7s - loss: 0.0441 - accuracy: 0.0417\n",
            "Epoch 7/20\n",
            "719/719 - 7s - loss: 0.0409 - accuracy: 0.0417\n",
            "Epoch 8/20\n",
            "719/719 - 7s - loss: 0.0388 - accuracy: 0.0417\n",
            "Epoch 9/20\n",
            "719/719 - 7s - loss: 0.0379 - accuracy: 0.0417\n",
            "Epoch 10/20\n",
            "719/719 - 7s - loss: 0.0350 - accuracy: 0.0417\n",
            "Epoch 11/20\n",
            "719/719 - 7s - loss: 0.0320 - accuracy: 0.0417\n",
            "Epoch 12/20\n",
            "719/719 - 7s - loss: 0.0305 - accuracy: 0.0417\n",
            "Epoch 13/20\n",
            "719/719 - 7s - loss: 0.0305 - accuracy: 0.0417\n",
            "Epoch 14/20\n",
            "719/719 - 7s - loss: 0.0307 - accuracy: 0.0417\n",
            "Epoch 15/20\n",
            "719/719 - 7s - loss: 0.0304 - accuracy: 0.0417\n",
            "Epoch 16/20\n",
            "719/719 - 7s - loss: 0.0300 - accuracy: 0.0417\n",
            "Epoch 17/20\n",
            "719/719 - 7s - loss: 0.0293 - accuracy: 0.0417\n",
            "Epoch 18/20\n",
            "719/719 - 7s - loss: 0.0294 - accuracy: 0.0417\n",
            "Epoch 19/20\n",
            "719/719 - 7s - loss: 0.0289 - accuracy: 0.0417\n",
            "Epoch 20/20\n",
            "719/719 - 7s - loss: 0.0290 - accuracy: 0.0417\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57b51a2d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.02794809639453888\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "719/719 - 7s - loss: 0.1539 - accuracy: 0.0139\n",
            "Epoch 2/20\n",
            "719/719 - 7s - loss: 0.1095 - accuracy: 0.0139\n",
            "Epoch 3/20\n",
            "719/719 - 7s - loss: 0.0834 - accuracy: 0.0139\n",
            "Epoch 4/20\n",
            "719/719 - 6s - loss: 0.0662 - accuracy: 0.0139\n",
            "Epoch 5/20\n",
            "719/719 - 7s - loss: 0.0569 - accuracy: 0.0139\n",
            "Epoch 6/20\n",
            "719/719 - 6s - loss: 0.0536 - accuracy: 0.0139\n",
            "Epoch 7/20\n",
            "719/719 - 7s - loss: 0.0503 - accuracy: 0.0139\n",
            "Epoch 8/20\n",
            "719/719 - 7s - loss: 0.0494 - accuracy: 0.0139\n",
            "Epoch 9/20\n",
            "719/719 - 7s - loss: 0.0467 - accuracy: 0.0139\n",
            "Epoch 10/20\n",
            "719/719 - 7s - loss: 0.0428 - accuracy: 0.0139\n",
            "Epoch 11/20\n",
            "719/719 - 7s - loss: 0.0422 - accuracy: 0.0139\n",
            "Epoch 12/20\n",
            "719/719 - 7s - loss: 0.0413 - accuracy: 0.0139\n",
            "Epoch 13/20\n",
            "719/719 - 7s - loss: 0.0409 - accuracy: 0.0139\n",
            "Epoch 14/20\n",
            "719/719 - 7s - loss: 0.0405 - accuracy: 0.0139\n",
            "Epoch 15/20\n",
            "719/719 - 7s - loss: 0.0396 - accuracy: 0.0139\n",
            "Epoch 16/20\n",
            "719/719 - 7s - loss: 0.0389 - accuracy: 0.0139\n",
            "Epoch 17/20\n",
            "719/719 - 7s - loss: 0.0376 - accuracy: 0.0139\n",
            "Epoch 18/20\n",
            "719/719 - 7s - loss: 0.0367 - accuracy: 0.0139\n",
            "Epoch 19/20\n",
            "719/719 - 7s - loss: 0.0376 - accuracy: 0.0139\n",
            "Epoch 20/20\n",
            "719/719 - 7s - loss: 0.0353 - accuracy: 0.0139\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57a74bdf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.020604832097887993\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "719/719 - 7s - loss: 0.1834 - accuracy: 0.0097\n",
            "Epoch 2/20\n",
            "719/719 - 7s - loss: 0.1054 - accuracy: 0.0097\n",
            "Epoch 3/20\n",
            "719/719 - 7s - loss: 0.0881 - accuracy: 0.0097\n",
            "Epoch 4/20\n",
            "719/719 - 7s - loss: 0.0779 - accuracy: 0.0097\n",
            "Epoch 5/20\n",
            "719/719 - 7s - loss: 0.0653 - accuracy: 0.0097\n",
            "Epoch 6/20\n",
            "719/719 - 7s - loss: 0.0596 - accuracy: 0.0097\n",
            "Epoch 7/20\n",
            "719/719 - 6s - loss: 0.0593 - accuracy: 0.0097\n",
            "Epoch 8/20\n",
            "719/719 - 7s - loss: 0.0545 - accuracy: 0.0097\n",
            "Epoch 9/20\n",
            "719/719 - 7s - loss: 0.0517 - accuracy: 0.0097\n",
            "Epoch 10/20\n",
            "719/719 - 6s - loss: 0.0515 - accuracy: 0.0097\n",
            "Epoch 11/20\n",
            "719/719 - 7s - loss: 0.0496 - accuracy: 0.0097\n",
            "Epoch 12/20\n",
            "719/719 - 7s - loss: 0.0482 - accuracy: 0.0097\n",
            "Epoch 13/20\n",
            "719/719 - 7s - loss: 0.0456 - accuracy: 0.0097\n",
            "Epoch 14/20\n",
            "719/719 - 7s - loss: 0.0434 - accuracy: 0.0097\n",
            "Epoch 15/20\n",
            "719/719 - 7s - loss: 0.0424 - accuracy: 0.0097\n",
            "Epoch 16/20\n",
            "719/719 - 7s - loss: 0.0426 - accuracy: 0.0097\n",
            "Epoch 17/20\n",
            "719/719 - 7s - loss: 0.0396 - accuracy: 0.0097\n",
            "Epoch 18/20\n",
            "719/719 - 7s - loss: 0.0407 - accuracy: 0.0097\n",
            "Epoch 19/20\n",
            "719/719 - 7s - loss: 0.0376 - accuracy: 0.0097\n",
            "Epoch 20/20\n",
            "719/719 - 7s - loss: 0.0373 - accuracy: 0.0097\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57af69fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.011959213763475418\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "719/719 - 7s - loss: 0.1646 - accuracy: 0.0028\n",
            "Epoch 2/20\n",
            "719/719 - 7s - loss: 0.1266 - accuracy: 0.0028\n",
            "Epoch 3/20\n",
            "719/719 - 7s - loss: 0.0868 - accuracy: 0.0028\n",
            "Epoch 4/20\n",
            "719/719 - 7s - loss: 0.0745 - accuracy: 0.0028\n",
            "Epoch 5/20\n",
            "719/719 - 7s - loss: 0.0693 - accuracy: 0.0028\n",
            "Epoch 6/20\n",
            "719/719 - 7s - loss: 0.0638 - accuracy: 0.0028\n",
            "Epoch 7/20\n",
            "719/719 - 7s - loss: 0.0599 - accuracy: 0.0028\n",
            "Epoch 8/20\n",
            "719/719 - 7s - loss: 0.0589 - accuracy: 0.0028\n",
            "Epoch 9/20\n",
            "719/719 - 7s - loss: 0.0569 - accuracy: 0.0028\n",
            "Epoch 10/20\n",
            "719/719 - 7s - loss: 0.0561 - accuracy: 0.0028\n",
            "Epoch 11/20\n",
            "719/719 - 7s - loss: 0.0543 - accuracy: 0.0028\n",
            "Epoch 12/20\n",
            "719/719 - 7s - loss: 0.0516 - accuracy: 0.0028\n",
            "Epoch 13/20\n",
            "719/719 - 7s - loss: 0.0541 - accuracy: 0.0028\n",
            "Epoch 14/20\n",
            "719/719 - 7s - loss: 0.0490 - accuracy: 0.0028\n",
            "Epoch 15/20\n",
            "719/719 - 7s - loss: 0.0476 - accuracy: 0.0028\n",
            "Epoch 16/20\n",
            "719/719 - 7s - loss: 0.0454 - accuracy: 0.0028\n",
            "Epoch 17/20\n",
            "719/719 - 7s - loss: 0.0428 - accuracy: 0.0028\n",
            "Epoch 18/20\n",
            "719/719 - 7s - loss: 0.0425 - accuracy: 0.0028\n",
            "Epoch 19/20\n",
            "719/719 - 7s - loss: 0.0423 - accuracy: 0.0028\n",
            "Epoch 20/20\n",
            "719/719 - 7s - loss: 0.0414 - accuracy: 0.0028\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57bb3882f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.006746028549969196\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "719/719 - 7s - loss: 0.1714 - accuracy: 0.0014\n",
            "Epoch 2/20\n",
            "719/719 - 7s - loss: 0.1245 - accuracy: 0.0014\n",
            "Epoch 3/20\n",
            "719/719 - 6s - loss: 0.0965 - accuracy: 0.0014\n",
            "Epoch 4/20\n",
            "719/719 - 6s - loss: 0.0832 - accuracy: 0.0014\n",
            "Epoch 5/20\n",
            "719/719 - 6s - loss: 0.0707 - accuracy: 0.0014\n",
            "Epoch 6/20\n",
            "719/719 - 7s - loss: 0.0652 - accuracy: 0.0014\n",
            "Epoch 7/20\n",
            "719/719 - 7s - loss: 0.0618 - accuracy: 0.0014\n",
            "Epoch 8/20\n",
            "719/719 - 7s - loss: 0.0597 - accuracy: 0.0014\n",
            "Epoch 9/20\n",
            "719/719 - 7s - loss: 0.0562 - accuracy: 0.0014\n",
            "Epoch 10/20\n",
            "719/719 - 6s - loss: 0.0565 - accuracy: 0.0014\n",
            "Epoch 11/20\n",
            "719/719 - 7s - loss: 0.0508 - accuracy: 0.0014\n",
            "Epoch 12/20\n",
            "719/719 - 7s - loss: 0.0470 - accuracy: 0.0014\n",
            "Epoch 13/20\n",
            "719/719 - 6s - loss: 0.0493 - accuracy: 0.0014\n",
            "Epoch 14/20\n",
            "719/719 - 7s - loss: 0.0470 - accuracy: 0.0014\n",
            "Epoch 15/20\n",
            "719/719 - 7s - loss: 0.0442 - accuracy: 0.0014\n",
            "Epoch 16/20\n",
            "719/719 - 6s - loss: 0.0460 - accuracy: 0.0014\n",
            "Epoch 17/20\n",
            "719/719 - 7s - loss: 0.0439 - accuracy: 0.0014\n",
            "Epoch 18/20\n",
            "719/719 - 7s - loss: 0.0417 - accuracy: 0.0014\n",
            "Epoch 19/20\n",
            "719/719 - 7s - loss: 0.0426 - accuracy: 0.0014\n",
            "Epoch 20/20\n",
            "719/719 - 7s - loss: 0.0406 - accuracy: 0.0014\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57b9419620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.007356896996498108\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "                   date   close          SMA  ...       MACD  MACD_signal  MACD_hist\n",
            "33  2017-11-15 09:00:00  1477.5  1514.023810  ...  -5.884713    -5.267630  -0.617083\n",
            "34  2017-11-16 09:00:00  1489.0  1513.833333  ...  -7.104850    -5.635074  -1.469776\n",
            "35  2017-11-17 09:00:00  1522.5  1516.666667  ...  -5.307466    -5.569552   0.262086\n",
            "36  2017-11-20 09:00:00  1527.5  1517.619048  ...  -3.439916    -5.143625   1.703709\n",
            "37  2017-11-21 09:00:00  1525.0  1519.095238  ...  -2.136964    -4.542293   2.405329\n",
            "..                  ...     ...          ...  ...        ...          ...        ...\n",
            "787 2020-11-30 09:00:00  4720.0  4686.666667  ...  11.473962    50.075913 -38.601951\n",
            "788 2020-12-01 09:00:00  4865.0  4693.571429  ...  32.220030    46.504737 -14.284707\n",
            "789 2020-12-02 09:00:00  4800.0  4697.619048  ...  42.921706    45.788131  -2.866424\n",
            "790 2020-12-03 09:00:00  4835.0  4717.380952  ...  53.609097    47.352324   6.256774\n",
            "791 2020-12-04 12:42:35  4660.0  4714.761905  ...  47.411366    47.364132   0.047233\n",
            "\n",
            "[759 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "699/699 - 9s - loss: 0.1162 - accuracy: 0.0358\n",
            "Epoch 2/20\n",
            "699/699 - 9s - loss: 0.0829 - accuracy: 0.0372\n",
            "Epoch 3/20\n",
            "699/699 - 9s - loss: 0.0635 - accuracy: 0.0372\n",
            "Epoch 4/20\n",
            "699/699 - 9s - loss: 0.0545 - accuracy: 0.0372\n",
            "Epoch 5/20\n",
            "699/699 - 9s - loss: 0.0486 - accuracy: 0.0372\n",
            "Epoch 6/20\n",
            "699/699 - 9s - loss: 0.0398 - accuracy: 0.0372\n",
            "Epoch 7/20\n",
            "699/699 - 9s - loss: 0.0377 - accuracy: 0.0372\n",
            "Epoch 8/20\n",
            "699/699 - 9s - loss: 0.0369 - accuracy: 0.0372\n",
            "Epoch 9/20\n",
            "699/699 - 9s - loss: 0.0356 - accuracy: 0.0372\n",
            "Epoch 10/20\n",
            "699/699 - 9s - loss: 0.0342 - accuracy: 0.0372\n",
            "Epoch 11/20\n",
            "699/699 - 9s - loss: 0.0324 - accuracy: 0.0372\n",
            "Epoch 12/20\n",
            "699/699 - 9s - loss: 0.0314 - accuracy: 0.0372\n",
            "Epoch 13/20\n",
            "699/699 - 9s - loss: 0.0320 - accuracy: 0.0372\n",
            "Epoch 14/20\n",
            "699/699 - 9s - loss: 0.0309 - accuracy: 0.0372\n",
            "Epoch 15/20\n",
            "699/699 - 9s - loss: 0.0298 - accuracy: 0.0372\n",
            "Epoch 16/20\n",
            "699/699 - 9s - loss: 0.0299 - accuracy: 0.0372\n",
            "Epoch 17/20\n",
            "699/699 - 9s - loss: 0.0298 - accuracy: 0.0372\n",
            "Epoch 18/20\n",
            "699/699 - 9s - loss: 0.0289 - accuracy: 0.0372\n",
            "Epoch 19/20\n",
            "699/699 - 9s - loss: 0.0294 - accuracy: 0.0372\n",
            "Epoch 20/20\n",
            "699/699 - 9s - loss: 0.0284 - accuracy: 0.0372\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57b57929d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.03244263678789139\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "699/699 - 9s - loss: 0.1733 - accuracy: 0.0129\n",
            "Epoch 2/20\n",
            "699/699 - 9s - loss: 0.1030 - accuracy: 0.0114\n",
            "Epoch 3/20\n",
            "699/699 - 9s - loss: 0.0768 - accuracy: 0.0129\n",
            "Epoch 4/20\n",
            "699/699 - 8s - loss: 0.0705 - accuracy: 0.0129\n",
            "Epoch 5/20\n",
            "699/699 - 9s - loss: 0.0559 - accuracy: 0.0129\n",
            "Epoch 6/20\n",
            "699/699 - 9s - loss: 0.0514 - accuracy: 0.0129\n",
            "Epoch 7/20\n",
            "699/699 - 8s - loss: 0.0521 - accuracy: 0.0129\n",
            "Epoch 8/20\n",
            "699/699 - 8s - loss: 0.0474 - accuracy: 0.0129\n",
            "Epoch 9/20\n",
            "699/699 - 8s - loss: 0.0468 - accuracy: 0.0129\n",
            "Epoch 10/20\n",
            "699/699 - 9s - loss: 0.0445 - accuracy: 0.0129\n",
            "Epoch 11/20\n",
            "699/699 - 8s - loss: 0.0436 - accuracy: 0.0129\n",
            "Epoch 12/20\n",
            "699/699 - 8s - loss: 0.0436 - accuracy: 0.0129\n",
            "Epoch 13/20\n",
            "699/699 - 9s - loss: 0.0414 - accuracy: 0.0129\n",
            "Epoch 14/20\n",
            "699/699 - 9s - loss: 0.0411 - accuracy: 0.0129\n",
            "Epoch 15/20\n",
            "699/699 - 8s - loss: 0.0403 - accuracy: 0.0129\n",
            "Epoch 16/20\n",
            "699/699 - 8s - loss: 0.0376 - accuracy: 0.0129\n",
            "Epoch 17/20\n",
            "699/699 - 9s - loss: 0.0362 - accuracy: 0.0129\n",
            "Epoch 18/20\n",
            "699/699 - 8s - loss: 0.0361 - accuracy: 0.0129\n",
            "Epoch 19/20\n",
            "699/699 - 9s - loss: 0.0359 - accuracy: 0.0129\n",
            "Epoch 20/20\n",
            "699/699 - 9s - loss: 0.0346 - accuracy: 0.0129\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57abc9b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.02314191497862339\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "699/699 - 9s - loss: 0.1462 - accuracy: 0.0100\n",
            "Epoch 2/20\n",
            "699/699 - 9s - loss: 0.0947 - accuracy: 0.0100\n",
            "Epoch 3/20\n",
            "699/699 - 9s - loss: 0.0830 - accuracy: 0.0100\n",
            "Epoch 4/20\n",
            "699/699 - 9s - loss: 0.0715 - accuracy: 0.0100\n",
            "Epoch 5/20\n",
            "699/699 - 9s - loss: 0.0633 - accuracy: 0.0100\n",
            "Epoch 6/20\n",
            "699/699 - 8s - loss: 0.0565 - accuracy: 0.0100\n",
            "Epoch 7/20\n",
            "699/699 - 9s - loss: 0.0573 - accuracy: 0.0100\n",
            "Epoch 8/20\n",
            "699/699 - 8s - loss: 0.0583 - accuracy: 0.0100\n",
            "Epoch 9/20\n",
            "699/699 - 8s - loss: 0.0504 - accuracy: 0.0100\n",
            "Epoch 10/20\n",
            "699/699 - 8s - loss: 0.0505 - accuracy: 0.0100\n",
            "Epoch 11/20\n",
            "699/699 - 8s - loss: 0.0504 - accuracy: 0.0100\n",
            "Epoch 12/20\n",
            "699/699 - 8s - loss: 0.0481 - accuracy: 0.0100\n",
            "Epoch 13/20\n",
            "699/699 - 9s - loss: 0.0430 - accuracy: 0.0100\n",
            "Epoch 14/20\n",
            "699/699 - 9s - loss: 0.0431 - accuracy: 0.0100\n",
            "Epoch 15/20\n",
            "699/699 - 9s - loss: 0.0438 - accuracy: 0.0100\n",
            "Epoch 16/20\n",
            "699/699 - 9s - loss: 0.0421 - accuracy: 0.0100\n",
            "Epoch 17/20\n",
            "699/699 - 9s - loss: 0.0409 - accuracy: 0.0100\n",
            "Epoch 18/20\n",
            "699/699 - 9s - loss: 0.0400 - accuracy: 0.0100\n",
            "Epoch 19/20\n",
            "699/699 - 9s - loss: 0.0387 - accuracy: 0.0100\n",
            "Epoch 20/20\n",
            "699/699 - 9s - loss: 0.0368 - accuracy: 0.0100\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57acfbdbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.017009640112519264\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "699/699 - 10s - loss: 0.1649 - accuracy: 0.0029\n",
            "Epoch 2/20\n",
            "699/699 - 10s - loss: 0.1154 - accuracy: 0.0029\n",
            "Epoch 3/20\n",
            "699/699 - 9s - loss: 0.0861 - accuracy: 0.0029\n",
            "Epoch 4/20\n",
            "699/699 - 9s - loss: 0.0820 - accuracy: 0.0029\n",
            "Epoch 5/20\n",
            "699/699 - 9s - loss: 0.0691 - accuracy: 0.0029\n",
            "Epoch 6/20\n",
            "699/699 - 9s - loss: 0.0636 - accuracy: 0.0029\n",
            "Epoch 7/20\n",
            "699/699 - 9s - loss: 0.0622 - accuracy: 0.0029\n",
            "Epoch 8/20\n",
            "699/699 - 9s - loss: 0.0617 - accuracy: 0.0029\n",
            "Epoch 9/20\n",
            "699/699 - 9s - loss: 0.0551 - accuracy: 0.0029\n",
            "Epoch 10/20\n",
            "699/699 - 9s - loss: 0.0571 - accuracy: 0.0029\n",
            "Epoch 11/20\n",
            "699/699 - 9s - loss: 0.0520 - accuracy: 0.0029\n",
            "Epoch 12/20\n",
            "699/699 - 9s - loss: 0.0477 - accuracy: 0.0029\n",
            "Epoch 13/20\n",
            "699/699 - 9s - loss: 0.0503 - accuracy: 0.0029\n",
            "Epoch 14/20\n",
            "699/699 - 9s - loss: 0.0479 - accuracy: 0.0029\n",
            "Epoch 15/20\n",
            "699/699 - 9s - loss: 0.0463 - accuracy: 0.0029\n",
            "Epoch 16/20\n",
            "699/699 - 8s - loss: 0.0456 - accuracy: 0.0029\n",
            "Epoch 17/20\n",
            "699/699 - 9s - loss: 0.0449 - accuracy: 0.0029\n",
            "Epoch 18/20\n",
            "699/699 - 8s - loss: 0.0431 - accuracy: 0.0029\n",
            "Epoch 19/20\n",
            "699/699 - 8s - loss: 0.0425 - accuracy: 0.0029\n",
            "Epoch 20/20\n",
            "699/699 - 9s - loss: 0.0414 - accuracy: 0.0029\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57b933b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.053082868456840515\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "699/699 - 9s - loss: 0.1652 - accuracy: 0.0014\n",
            "Epoch 2/20\n",
            "699/699 - 9s - loss: 0.1145 - accuracy: 0.0014\n",
            "Epoch 3/20\n",
            "699/699 - 9s - loss: 0.0917 - accuracy: 0.0014\n",
            "Epoch 4/20\n",
            "699/699 - 9s - loss: 0.0825 - accuracy: 0.0014\n",
            "Epoch 5/20\n",
            "699/699 - 9s - loss: 0.0764 - accuracy: 0.0014\n",
            "Epoch 6/20\n",
            "699/699 - 9s - loss: 0.0692 - accuracy: 0.0014\n",
            "Epoch 7/20\n",
            "699/699 - 9s - loss: 0.0688 - accuracy: 0.0014\n",
            "Epoch 8/20\n",
            "699/699 - 9s - loss: 0.0616 - accuracy: 0.0014\n",
            "Epoch 9/20\n",
            "699/699 - 8s - loss: 0.0619 - accuracy: 0.0014\n",
            "Epoch 10/20\n",
            "699/699 - 9s - loss: 0.0583 - accuracy: 0.0014\n",
            "Epoch 11/20\n",
            "699/699 - 8s - loss: 0.0561 - accuracy: 0.0014\n",
            "Epoch 12/20\n",
            "699/699 - 9s - loss: 0.0527 - accuracy: 0.0014\n",
            "Epoch 13/20\n",
            "699/699 - 8s - loss: 0.0524 - accuracy: 0.0014\n",
            "Epoch 14/20\n",
            "699/699 - 8s - loss: 0.0481 - accuracy: 0.0014\n",
            "Epoch 15/20\n",
            "699/699 - 8s - loss: 0.0501 - accuracy: 0.0014\n",
            "Epoch 16/20\n",
            "699/699 - 9s - loss: 0.0459 - accuracy: 0.0014\n",
            "Epoch 17/20\n",
            "699/699 - 9s - loss: 0.0461 - accuracy: 0.0014\n",
            "Epoch 18/20\n",
            "699/699 - 9s - loss: 0.0426 - accuracy: 0.0014\n",
            "Epoch 19/20\n",
            "699/699 - 8s - loss: 0.0435 - accuracy: 0.0014\n",
            "Epoch 20/20\n",
            "699/699 - 9s - loss: 0.0419 - accuracy: 0.0014\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57a7103e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.017114080488681793\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "ループ回数: 2\n",
            "4478\n",
            "                   date   close  ...  MACD_signal  MACD_hist\n",
            "33  2020-02-07 09:00:00  3295.0  ...    15.923053   5.953572\n",
            "34  2020-02-10 09:00:00  3300.0  ...    18.083432   8.641517\n",
            "35  2020-02-12 09:00:00  3415.0  ...    22.345291  17.047435\n",
            "36  2020-02-13 09:00:00  3530.0  ...    29.484731  28.557760\n",
            "37  2020-02-14 09:00:00  3535.0  ...    38.066092  34.325446\n",
            "..                  ...     ...  ...          ...        ...\n",
            "229 2020-11-30 09:00:00  9220.0  ...   187.982973  52.727044\n",
            "230 2020-12-01 09:00:00  9820.0  ...   210.042947  88.239897\n",
            "231 2020-12-02 09:00:00  9350.0  ...   228.533887  73.963760\n",
            "232 2020-12-03 09:00:00  9200.0  ...   240.904463  49.482303\n",
            "233 2020-12-04 12:57:42  9580.0  ...   254.304035  53.598288\n",
            "\n",
            "[201 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "181/181 - 1s - loss: 0.1863 - accuracy: 0.0387\n",
            "Epoch 2/20\n",
            "181/181 - 1s - loss: 0.1732 - accuracy: 0.0387\n",
            "Epoch 3/20\n",
            "181/181 - 1s - loss: 0.1346 - accuracy: 0.0387\n",
            "Epoch 4/20\n",
            "181/181 - 1s - loss: 0.0920 - accuracy: 0.0387\n",
            "Epoch 5/20\n",
            "181/181 - 1s - loss: 0.0909 - accuracy: 0.0387\n",
            "Epoch 6/20\n",
            "181/181 - 1s - loss: 0.0627 - accuracy: 0.0387\n",
            "Epoch 7/20\n",
            "181/181 - 1s - loss: 0.0725 - accuracy: 0.0387\n",
            "Epoch 8/20\n",
            "181/181 - 1s - loss: 0.0628 - accuracy: 0.0387\n",
            "Epoch 9/20\n",
            "181/181 - 1s - loss: 0.0882 - accuracy: 0.0387\n",
            "Epoch 10/20\n",
            "181/181 - 1s - loss: 0.0746 - accuracy: 0.0387\n",
            "Epoch 11/20\n",
            "181/181 - 1s - loss: 0.0594 - accuracy: 0.0387\n",
            "Epoch 12/20\n",
            "181/181 - 1s - loss: 0.0558 - accuracy: 0.0387\n",
            "Epoch 13/20\n",
            "181/181 - 1s - loss: 0.0488 - accuracy: 0.0387\n",
            "Epoch 14/20\n",
            "181/181 - 1s - loss: 0.0512 - accuracy: 0.0387\n",
            "Epoch 15/20\n",
            "181/181 - 1s - loss: 0.0491 - accuracy: 0.0387\n",
            "Epoch 16/20\n",
            "181/181 - 1s - loss: 0.0493 - accuracy: 0.0387\n",
            "Epoch 17/20\n",
            "181/181 - 1s - loss: 0.0437 - accuracy: 0.0387\n",
            "Epoch 18/20\n",
            "181/181 - 1s - loss: 0.0481 - accuracy: 0.0387\n",
            "Epoch 19/20\n",
            "181/181 - 1s - loss: 0.0464 - accuracy: 0.0387\n",
            "Epoch 20/20\n",
            "181/181 - 1s - loss: 0.0453 - accuracy: 0.0387\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57ad7a40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.03791312128305435\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "181/181 - 1s - loss: 0.1534 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "181/181 - 1s - loss: 0.1689 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "181/181 - 1s - loss: 0.1395 - accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "181/181 - 1s - loss: 0.1317 - accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "181/181 - 1s - loss: 0.1073 - accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "181/181 - 1s - loss: 0.1048 - accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "181/181 - 1s - loss: 0.0953 - accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "181/181 - 1s - loss: 0.0788 - accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "181/181 - 1s - loss: 0.0692 - accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "181/181 - 1s - loss: 0.0690 - accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "181/181 - 1s - loss: 0.0711 - accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "181/181 - 1s - loss: 0.0631 - accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "181/181 - 1s - loss: 0.0629 - accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "181/181 - 1s - loss: 0.0621 - accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "181/181 - 1s - loss: 0.0558 - accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "181/181 - 1s - loss: 0.0551 - accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "181/181 - 1s - loss: 0.0486 - accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "181/181 - 1s - loss: 0.0510 - accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "181/181 - 1s - loss: 0.0565 - accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "181/181 - 1s - loss: 0.0575 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57aaae9510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.02509002946317196\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "181/181 - 1s - loss: 0.1838 - accuracy: 0.0166\n",
            "Epoch 2/20\n",
            "181/181 - 1s - loss: 0.2099 - accuracy: 0.0166\n",
            "Epoch 3/20\n",
            "181/181 - 1s - loss: 0.1468 - accuracy: 0.0166\n",
            "Epoch 4/20\n",
            "181/181 - 1s - loss: 0.1335 - accuracy: 0.0166\n",
            "Epoch 5/20\n",
            "181/181 - 1s - loss: 0.1008 - accuracy: 0.0166\n",
            "Epoch 6/20\n",
            "181/181 - 1s - loss: 0.0991 - accuracy: 0.0166\n",
            "Epoch 7/20\n",
            "181/181 - 1s - loss: 0.0845 - accuracy: 0.0166\n",
            "Epoch 8/20\n",
            "181/181 - 1s - loss: 0.0897 - accuracy: 0.0166\n",
            "Epoch 9/20\n",
            "181/181 - 1s - loss: 0.0816 - accuracy: 0.0166\n",
            "Epoch 10/20\n",
            "181/181 - 1s - loss: 0.0747 - accuracy: 0.0166\n",
            "Epoch 11/20\n",
            "181/181 - 1s - loss: 0.0605 - accuracy: 0.0166\n",
            "Epoch 12/20\n",
            "181/181 - 1s - loss: 0.0727 - accuracy: 0.0166\n",
            "Epoch 13/20\n",
            "181/181 - 1s - loss: 0.0657 - accuracy: 0.0166\n",
            "Epoch 14/20\n",
            "181/181 - 1s - loss: 0.0661 - accuracy: 0.0166\n",
            "Epoch 15/20\n",
            "181/181 - 1s - loss: 0.0600 - accuracy: 0.0166\n",
            "Epoch 16/20\n",
            "181/181 - 1s - loss: 0.0586 - accuracy: 0.0166\n",
            "Epoch 17/20\n",
            "181/181 - 1s - loss: 0.0578 - accuracy: 0.0166\n",
            "Epoch 18/20\n",
            "181/181 - 1s - loss: 0.0550 - accuracy: 0.0166\n",
            "Epoch 19/20\n",
            "181/181 - 1s - loss: 0.0545 - accuracy: 0.0166\n",
            "Epoch 20/20\n",
            "181/181 - 1s - loss: 0.0528 - accuracy: 0.0166\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57a844cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.05348121374845505\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "181/181 - 1s - loss: 0.1596 - accuracy: 0.0055\n",
            "Epoch 2/20\n",
            "181/181 - 1s - loss: 0.1686 - accuracy: 0.0055\n",
            "Epoch 3/20\n",
            "181/181 - 1s - loss: 0.1437 - accuracy: 0.0055\n",
            "Epoch 4/20\n",
            "181/181 - 1s - loss: 0.1231 - accuracy: 0.0055\n",
            "Epoch 5/20\n",
            "181/181 - 1s - loss: 0.1013 - accuracy: 0.0055\n",
            "Epoch 6/20\n",
            "181/181 - 1s - loss: 0.0922 - accuracy: 0.0055\n",
            "Epoch 7/20\n",
            "181/181 - 1s - loss: 0.0948 - accuracy: 0.0055\n",
            "Epoch 8/20\n",
            "181/181 - 1s - loss: 0.0965 - accuracy: 0.0055\n",
            "Epoch 9/20\n",
            "181/181 - 1s - loss: 0.0827 - accuracy: 0.0055\n",
            "Epoch 10/20\n",
            "181/181 - 1s - loss: 0.0704 - accuracy: 0.0055\n",
            "Epoch 11/20\n",
            "181/181 - 1s - loss: 0.0681 - accuracy: 0.0055\n",
            "Epoch 12/20\n",
            "181/181 - 1s - loss: 0.0748 - accuracy: 0.0055\n",
            "Epoch 13/20\n",
            "181/181 - 1s - loss: 0.0775 - accuracy: 0.0055\n",
            "Epoch 14/20\n",
            "181/181 - 1s - loss: 0.0676 - accuracy: 0.0055\n",
            "Epoch 15/20\n",
            "181/181 - 1s - loss: 0.0646 - accuracy: 0.0055\n",
            "Epoch 16/20\n",
            "181/181 - 1s - loss: 0.0660 - accuracy: 0.0055\n",
            "Epoch 17/20\n",
            "181/181 - 1s - loss: 0.0652 - accuracy: 0.0055\n",
            "Epoch 18/20\n",
            "181/181 - 1s - loss: 0.0560 - accuracy: 0.0055\n",
            "Epoch 19/20\n",
            "181/181 - 1s - loss: 0.0636 - accuracy: 0.0055\n",
            "Epoch 20/20\n",
            "181/181 - 1s - loss: 0.0623 - accuracy: 0.0055\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57a7bf1048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.07830516993999481\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "181/181 - 1s - loss: 0.1667 - accuracy: 0.0055\n",
            "Epoch 2/20\n",
            "181/181 - 1s - loss: 0.1857 - accuracy: 0.0055\n",
            "Epoch 3/20\n",
            "181/181 - 1s - loss: 0.1331 - accuracy: 0.0055\n",
            "Epoch 4/20\n",
            "181/181 - 1s - loss: 0.1156 - accuracy: 0.0055\n",
            "Epoch 5/20\n",
            "181/181 - 1s - loss: 0.0945 - accuracy: 0.0055\n",
            "Epoch 6/20\n",
            "181/181 - 1s - loss: 0.1027 - accuracy: 0.0055\n",
            "Epoch 7/20\n",
            "181/181 - 1s - loss: 0.0948 - accuracy: 0.0055\n",
            "Epoch 8/20\n",
            "181/181 - 1s - loss: 0.0935 - accuracy: 0.0055\n",
            "Epoch 9/20\n",
            "181/181 - 1s - loss: 0.0881 - accuracy: 0.0055\n",
            "Epoch 10/20\n",
            "181/181 - 1s - loss: 0.0858 - accuracy: 0.0055\n",
            "Epoch 11/20\n",
            "181/181 - 1s - loss: 0.0699 - accuracy: 0.0055\n",
            "Epoch 12/20\n",
            "181/181 - 1s - loss: 0.0690 - accuracy: 0.0055\n",
            "Epoch 13/20\n",
            "181/181 - 1s - loss: 0.0773 - accuracy: 0.0055\n",
            "Epoch 14/20\n",
            "181/181 - 1s - loss: 0.0679 - accuracy: 0.0055\n",
            "Epoch 15/20\n",
            "181/181 - 1s - loss: 0.0591 - accuracy: 0.0055\n",
            "Epoch 16/20\n",
            "181/181 - 1s - loss: 0.0677 - accuracy: 0.0055\n",
            "Epoch 17/20\n",
            "181/181 - 1s - loss: 0.0638 - accuracy: 0.0055\n",
            "Epoch 18/20\n",
            "181/181 - 1s - loss: 0.0582 - accuracy: 0.0055\n",
            "Epoch 19/20\n",
            "181/181 - 1s - loss: 0.0573 - accuracy: 0.0055\n",
            "Epoch 20/20\n",
            "181/181 - 1s - loss: 0.0558 - accuracy: 0.0055\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57be8e2730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.060792118310928345\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "                   date   close  ...  MACD_signal  MACD_hist\n",
            "33  2020-02-07 09:00:00  3295.0  ...    15.923053   5.953572\n",
            "34  2020-02-10 09:00:00  3300.0  ...    18.083432   8.641517\n",
            "35  2020-02-12 09:00:00  3415.0  ...    22.345291  17.047435\n",
            "36  2020-02-13 09:00:00  3530.0  ...    29.484731  28.557760\n",
            "37  2020-02-14 09:00:00  3535.0  ...    38.066092  34.325446\n",
            "..                  ...     ...  ...          ...        ...\n",
            "229 2020-11-30 09:00:00  9220.0  ...   187.982973  52.727044\n",
            "230 2020-12-01 09:00:00  9820.0  ...   210.042947  88.239897\n",
            "231 2020-12-02 09:00:00  9350.0  ...   228.533887  73.963760\n",
            "232 2020-12-03 09:00:00  9200.0  ...   240.904463  49.482303\n",
            "233 2020-12-04 12:59:31  9560.0  ...   253.984946  52.321934\n",
            "\n",
            "[201 rows x 11 columns]\n",
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "161/161 - 2s - loss: 0.1899 - accuracy: 0.0435\n",
            "Epoch 2/20\n",
            "161/161 - 2s - loss: 0.2142 - accuracy: 0.0435\n",
            "Epoch 3/20\n",
            "161/161 - 2s - loss: 0.1426 - accuracy: 0.0435\n",
            "Epoch 4/20\n",
            "161/161 - 2s - loss: 0.1039 - accuracy: 0.0435\n",
            "Epoch 5/20\n",
            "161/161 - 1s - loss: 0.1046 - accuracy: 0.0435\n",
            "Epoch 6/20\n",
            "161/161 - 1s - loss: 0.1181 - accuracy: 0.0435\n",
            "Epoch 7/20\n",
            "161/161 - 1s - loss: 0.0714 - accuracy: 0.0435\n",
            "Epoch 8/20\n",
            "161/161 - 2s - loss: 0.0698 - accuracy: 0.0435\n",
            "Epoch 9/20\n",
            "161/161 - 2s - loss: 0.0646 - accuracy: 0.0435\n",
            "Epoch 10/20\n",
            "161/161 - 2s - loss: 0.0685 - accuracy: 0.0435\n",
            "Epoch 11/20\n",
            "161/161 - 1s - loss: 0.0694 - accuracy: 0.0435\n",
            "Epoch 12/20\n",
            "161/161 - 2s - loss: 0.0490 - accuracy: 0.0435\n",
            "Epoch 13/20\n",
            "161/161 - 2s - loss: 0.0650 - accuracy: 0.0435\n",
            "Epoch 14/20\n",
            "161/161 - 1s - loss: 0.0634 - accuracy: 0.0435\n",
            "Epoch 15/20\n",
            "161/161 - 1s - loss: 0.0547 - accuracy: 0.0435\n",
            "Epoch 16/20\n",
            "161/161 - 1s - loss: 0.0467 - accuracy: 0.0435\n",
            "Epoch 17/20\n",
            "161/161 - 2s - loss: 0.0488 - accuracy: 0.0435\n",
            "Epoch 18/20\n",
            "161/161 - 2s - loss: 0.0523 - accuracy: 0.0435\n",
            "Epoch 19/20\n",
            "161/161 - 2s - loss: 0.0576 - accuracy: 0.0435\n",
            "Epoch 20/20\n",
            "161/161 - 2s - loss: 0.0502 - accuracy: 0.0435\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57bd4391e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.02352496236562729\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "161/161 - 2s - loss: 0.1702 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "161/161 - 2s - loss: 0.1667 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "161/161 - 2s - loss: 0.1256 - accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "161/161 - 1s - loss: 0.1887 - accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "161/161 - 1s - loss: 0.1099 - accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "161/161 - 1s - loss: 0.1020 - accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "161/161 - 1s - loss: 0.0935 - accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "161/161 - 2s - loss: 0.0679 - accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "161/161 - 1s - loss: 0.1165 - accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "161/161 - 2s - loss: 0.0684 - accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "161/161 - 1s - loss: 0.0898 - accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "161/161 - 1s - loss: 0.0732 - accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "161/161 - 1s - loss: 0.0588 - accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "161/161 - 1s - loss: 0.0736 - accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "161/161 - 1s - loss: 0.0644 - accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "161/161 - 2s - loss: 0.0574 - accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "161/161 - 1s - loss: 0.0733 - accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "161/161 - 1s - loss: 0.0539 - accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "161/161 - 2s - loss: 0.0673 - accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "161/161 - 1s - loss: 0.0648 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57b29cfc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.05174645781517029\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "161/161 - 1s - loss: 0.2443 - accuracy: 0.0186\n",
            "Epoch 2/20\n",
            "161/161 - 2s - loss: 0.1753 - accuracy: 0.0186\n",
            "Epoch 3/20\n",
            "161/161 - 2s - loss: 0.1283 - accuracy: 0.0186\n",
            "Epoch 4/20\n",
            "161/161 - 2s - loss: 0.1185 - accuracy: 0.0186\n",
            "Epoch 5/20\n",
            "161/161 - 2s - loss: 0.1224 - accuracy: 0.0186\n",
            "Epoch 6/20\n",
            "161/161 - 2s - loss: 0.1106 - accuracy: 0.0186\n",
            "Epoch 7/20\n",
            "161/161 - 2s - loss: 0.1098 - accuracy: 0.0186\n",
            "Epoch 8/20\n",
            "161/161 - 2s - loss: 0.0866 - accuracy: 0.0186\n",
            "Epoch 9/20\n",
            "161/161 - 2s - loss: 0.0767 - accuracy: 0.0186\n",
            "Epoch 10/20\n",
            "161/161 - 2s - loss: 0.0969 - accuracy: 0.0186\n",
            "Epoch 11/20\n",
            "161/161 - 2s - loss: 0.0953 - accuracy: 0.0186\n",
            "Epoch 12/20\n",
            "161/161 - 2s - loss: 0.0748 - accuracy: 0.0186\n",
            "Epoch 13/20\n",
            "161/161 - 2s - loss: 0.0728 - accuracy: 0.0186\n",
            "Epoch 14/20\n",
            "161/161 - 2s - loss: 0.0667 - accuracy: 0.0186\n",
            "Epoch 15/20\n",
            "161/161 - 2s - loss: 0.0663 - accuracy: 0.0186\n",
            "Epoch 16/20\n",
            "161/161 - 1s - loss: 0.0677 - accuracy: 0.0186\n",
            "Epoch 17/20\n",
            "161/161 - 1s - loss: 0.0606 - accuracy: 0.0186\n",
            "Epoch 18/20\n",
            "161/161 - 1s - loss: 0.0603 - accuracy: 0.0186\n",
            "Epoch 19/20\n",
            "161/161 - 1s - loss: 0.0548 - accuracy: 0.0186\n",
            "Epoch 20/20\n",
            "161/161 - 1s - loss: 0.0581 - accuracy: 0.0186\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57a7fc1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.006599027663469315\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "161/161 - 2s - loss: 0.2401 - accuracy: 0.0062\n",
            "Epoch 2/20\n",
            "161/161 - 2s - loss: 0.1948 - accuracy: 0.0062\n",
            "Epoch 3/20\n",
            "161/161 - 1s - loss: 0.1364 - accuracy: 0.0062\n",
            "Epoch 4/20\n",
            "161/161 - 1s - loss: 0.1335 - accuracy: 0.0062\n",
            "Epoch 5/20\n",
            "161/161 - 1s - loss: 0.1190 - accuracy: 0.0062\n",
            "Epoch 6/20\n",
            "161/161 - 1s - loss: 0.1281 - accuracy: 0.0062\n",
            "Epoch 7/20\n",
            "161/161 - 1s - loss: 0.1134 - accuracy: 0.0062\n",
            "Epoch 8/20\n",
            "161/161 - 1s - loss: 0.0802 - accuracy: 0.0062\n",
            "Epoch 9/20\n",
            "161/161 - 1s - loss: 0.0847 - accuracy: 0.0062\n",
            "Epoch 10/20\n",
            "161/161 - 1s - loss: 0.0749 - accuracy: 0.0062\n",
            "Epoch 11/20\n",
            "161/161 - 1s - loss: 0.0789 - accuracy: 0.0062\n",
            "Epoch 12/20\n",
            "161/161 - 1s - loss: 0.0789 - accuracy: 0.0062\n",
            "Epoch 13/20\n",
            "161/161 - 2s - loss: 0.0793 - accuracy: 0.0062\n",
            "Epoch 14/20\n",
            "161/161 - 1s - loss: 0.0784 - accuracy: 0.0062\n",
            "Epoch 15/20\n",
            "161/161 - 1s - loss: 0.0643 - accuracy: 0.0062\n",
            "Epoch 16/20\n",
            "161/161 - 1s - loss: 0.0591 - accuracy: 0.0062\n",
            "Epoch 17/20\n",
            "161/161 - 2s - loss: 0.0686 - accuracy: 0.0062\n",
            "Epoch 18/20\n",
            "161/161 - 2s - loss: 0.0606 - accuracy: 0.0062\n",
            "Epoch 19/20\n",
            "161/161 - 2s - loss: 0.0691 - accuracy: 0.0062\n",
            "Epoch 20/20\n",
            "161/161 - 2s - loss: 0.0613 - accuracy: 0.0062\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57ad41a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.0454704686999321\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "161/161 - 2s - loss: 0.2067 - accuracy: 0.0062\n",
            "Epoch 2/20\n",
            "161/161 - 2s - loss: 0.1889 - accuracy: 0.0062\n",
            "Epoch 3/20\n",
            "161/161 - 2s - loss: 0.1530 - accuracy: 0.0062\n",
            "Epoch 4/20\n",
            "161/161 - 2s - loss: 0.1357 - accuracy: 0.0062\n",
            "Epoch 5/20\n",
            "161/161 - 1s - loss: 0.1368 - accuracy: 0.0062\n",
            "Epoch 6/20\n",
            "161/161 - 1s - loss: 0.1405 - accuracy: 0.0062\n",
            "Epoch 7/20\n",
            "161/161 - 2s - loss: 0.1130 - accuracy: 0.0062\n",
            "Epoch 8/20\n",
            "161/161 - 1s - loss: 0.0931 - accuracy: 0.0062\n",
            "Epoch 9/20\n",
            "161/161 - 1s - loss: 0.0925 - accuracy: 0.0062\n",
            "Epoch 10/20\n",
            "161/161 - 1s - loss: 0.0897 - accuracy: 0.0062\n",
            "Epoch 11/20\n",
            "161/161 - 1s - loss: 0.0999 - accuracy: 0.0062\n",
            "Epoch 12/20\n",
            "161/161 - 1s - loss: 0.0928 - accuracy: 0.0062\n",
            "Epoch 13/20\n",
            "161/161 - 1s - loss: 0.0892 - accuracy: 0.0062\n",
            "Epoch 14/20\n",
            "161/161 - 1s - loss: 0.1008 - accuracy: 0.0062\n",
            "Epoch 15/20\n",
            "161/161 - 2s - loss: 0.0668 - accuracy: 0.0062\n",
            "Epoch 16/20\n",
            "161/161 - 1s - loss: 0.0826 - accuracy: 0.0062\n",
            "Epoch 17/20\n",
            "161/161 - 2s - loss: 0.0605 - accuracy: 0.0062\n",
            "Epoch 18/20\n",
            "161/161 - 2s - loss: 0.0635 - accuracy: 0.0062\n",
            "Epoch 19/20\n",
            "161/161 - 2s - loss: 0.0655 - accuracy: 0.0062\n",
            "Epoch 20/20\n",
            "161/161 - 2s - loss: 0.0773 - accuracy: 0.0062\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57ae577b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.1290930211544037\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "                   date   close  ...  MACD_signal  MACD_hist\n",
            "33  2020-02-07 09:00:00  3295.0  ...    15.923053   5.953572\n",
            "34  2020-02-10 09:00:00  3300.0  ...    18.083432   8.641517\n",
            "35  2020-02-12 09:00:00  3415.0  ...    22.345291  17.047435\n",
            "36  2020-02-13 09:00:00  3530.0  ...    29.484731  28.557760\n",
            "37  2020-02-14 09:00:00  3535.0  ...    38.066092  34.325446\n",
            "..                  ...     ...  ...          ...        ...\n",
            "229 2020-11-30 09:00:00  9220.0  ...   187.982973  52.727044\n",
            "230 2020-12-01 09:00:00  9820.0  ...   210.042947  88.239897\n",
            "231 2020-12-02 09:00:00  9350.0  ...   228.533887  73.963760\n",
            "232 2020-12-03 09:00:00  9200.0  ...   240.904463  49.482303\n",
            "233 2020-12-04 13:02:34  9530.0  ...   253.506314  50.407404\n",
            "\n",
            "[201 rows x 11 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "141/141 - 2s - loss: 0.2496 - accuracy: 0.0355\n",
            "Epoch 2/20\n",
            "141/141 - 2s - loss: 0.2230 - accuracy: 0.0355\n",
            "Epoch 3/20\n",
            "141/141 - 2s - loss: 0.1134 - accuracy: 0.0284\n",
            "Epoch 4/20\n",
            "141/141 - 2s - loss: 0.1671 - accuracy: 0.0213\n",
            "Epoch 5/20\n",
            "141/141 - 2s - loss: 0.0902 - accuracy: 0.0355\n",
            "Epoch 6/20\n",
            "141/141 - 2s - loss: 0.1069 - accuracy: 0.0284\n",
            "Epoch 7/20\n",
            "141/141 - 2s - loss: 0.0822 - accuracy: 0.0355\n",
            "Epoch 8/20\n",
            "141/141 - 2s - loss: 0.0780 - accuracy: 0.0355\n",
            "Epoch 9/20\n",
            "141/141 - 2s - loss: 0.0618 - accuracy: 0.0355\n",
            "Epoch 10/20\n",
            "141/141 - 2s - loss: 0.0612 - accuracy: 0.0355\n",
            "Epoch 11/20\n",
            "141/141 - 2s - loss: 0.0573 - accuracy: 0.0355\n",
            "Epoch 12/20\n",
            "141/141 - 2s - loss: 0.0605 - accuracy: 0.0355\n",
            "Epoch 13/20\n",
            "141/141 - 2s - loss: 0.0622 - accuracy: 0.0355\n",
            "Epoch 14/20\n",
            "141/141 - 2s - loss: 0.0572 - accuracy: 0.0355\n",
            "Epoch 15/20\n",
            "141/141 - 2s - loss: 0.0510 - accuracy: 0.0355\n",
            "Epoch 16/20\n",
            "141/141 - 2s - loss: 0.0428 - accuracy: 0.0355\n",
            "Epoch 17/20\n",
            "141/141 - 2s - loss: 0.0401 - accuracy: 0.0355\n",
            "Epoch 18/20\n",
            "141/141 - 2s - loss: 0.0453 - accuracy: 0.0355\n",
            "Epoch 19/20\n",
            "141/141 - 2s - loss: 0.0519 - accuracy: 0.0355\n",
            "Epoch 20/20\n",
            "141/141 - 2s - loss: 0.0378 - accuracy: 0.0355\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57ac003268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.029120419174432755\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "141/141 - 2s - loss: 0.1983 - accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "141/141 - 2s - loss: 0.2298 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "141/141 - 2s - loss: 0.1680 - accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "141/141 - 2s - loss: 0.1369 - accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "141/141 - 2s - loss: 0.1194 - accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "141/141 - 2s - loss: 0.1068 - accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "141/141 - 2s - loss: 0.0978 - accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "141/141 - 2s - loss: 0.0835 - accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "141/141 - 2s - loss: 0.0803 - accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "141/141 - 2s - loss: 0.0762 - accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "141/141 - 2s - loss: 0.0559 - accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "141/141 - 2s - loss: 0.0553 - accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "141/141 - 2s - loss: 0.0688 - accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "141/141 - 2s - loss: 0.0601 - accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "141/141 - 2s - loss: 0.0599 - accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "141/141 - 2s - loss: 0.0499 - accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "141/141 - 2s - loss: 0.0491 - accuracy: 0.0000e+00\n",
            "Epoch 18/20\n",
            "141/141 - 2s - loss: 0.0423 - accuracy: 0.0000e+00\n",
            "Epoch 19/20\n",
            "141/141 - 2s - loss: 0.0509 - accuracy: 0.0000e+00\n",
            "Epoch 20/20\n",
            "141/141 - 2s - loss: 0.0530 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57b8e70f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.031976401805877686\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "141/141 - 2s - loss: 0.1426 - accuracy: 0.0142\n",
            "Epoch 2/20\n",
            "141/141 - 2s - loss: 0.2414 - accuracy: 0.0142\n",
            "Epoch 3/20\n",
            "141/141 - 2s - loss: 0.1695 - accuracy: 0.0142\n",
            "Epoch 4/20\n",
            "141/141 - 2s - loss: 0.1677 - accuracy: 0.0142\n",
            "Epoch 5/20\n",
            "141/141 - 2s - loss: 0.1259 - accuracy: 0.0142\n",
            "Epoch 6/20\n",
            "141/141 - 2s - loss: 0.0863 - accuracy: 0.0142\n",
            "Epoch 7/20\n",
            "141/141 - 2s - loss: 0.0944 - accuracy: 0.0142\n",
            "Epoch 8/20\n",
            "141/141 - 2s - loss: 0.0844 - accuracy: 0.0142\n",
            "Epoch 9/20\n",
            "141/141 - 2s - loss: 0.0852 - accuracy: 0.0142\n",
            "Epoch 10/20\n",
            "141/141 - 2s - loss: 0.0897 - accuracy: 0.0142\n",
            "Epoch 11/20\n",
            "141/141 - 2s - loss: 0.0779 - accuracy: 0.0142\n",
            "Epoch 12/20\n",
            "141/141 - 2s - loss: 0.0742 - accuracy: 0.0142\n",
            "Epoch 13/20\n",
            "141/141 - 2s - loss: 0.0646 - accuracy: 0.0142\n",
            "Epoch 14/20\n",
            "141/141 - 2s - loss: 0.0620 - accuracy: 0.0142\n",
            "Epoch 15/20\n",
            "141/141 - 2s - loss: 0.0626 - accuracy: 0.0142\n",
            "Epoch 16/20\n",
            "141/141 - 2s - loss: 0.0619 - accuracy: 0.0142\n",
            "Epoch 17/20\n",
            "141/141 - 2s - loss: 0.0560 - accuracy: 0.0142\n",
            "Epoch 18/20\n",
            "141/141 - 2s - loss: 0.0477 - accuracy: 0.0142\n",
            "Epoch 19/20\n",
            "141/141 - 2s - loss: 0.0496 - accuracy: 0.0142\n",
            "Epoch 20/20\n",
            "141/141 - 2s - loss: 0.0531 - accuracy: 0.0142\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57b5eff6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.04820594936609268\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "141/141 - 2s - loss: 0.2341 - accuracy: 0.0071\n",
            "Epoch 2/20\n",
            "141/141 - 2s - loss: 0.1945 - accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "141/141 - 2s - loss: 0.1823 - accuracy: 0.0071\n",
            "Epoch 4/20\n",
            "141/141 - 2s - loss: 0.1938 - accuracy: 0.0071\n",
            "Epoch 5/20\n",
            "141/141 - 2s - loss: 0.1302 - accuracy: 0.0071\n",
            "Epoch 6/20\n",
            "141/141 - 2s - loss: 0.1334 - accuracy: 0.0071\n",
            "Epoch 7/20\n",
            "141/141 - 2s - loss: 0.1348 - accuracy: 0.0071\n",
            "Epoch 8/20\n",
            "141/141 - 2s - loss: 0.1054 - accuracy: 0.0071\n",
            "Epoch 9/20\n",
            "141/141 - 2s - loss: 0.0968 - accuracy: 0.0071\n",
            "Epoch 10/20\n",
            "141/141 - 2s - loss: 0.0801 - accuracy: 0.0071\n",
            "Epoch 11/20\n",
            "141/141 - 2s - loss: 0.0914 - accuracy: 0.0071\n",
            "Epoch 12/20\n",
            "141/141 - 2s - loss: 0.0776 - accuracy: 0.0071\n",
            "Epoch 13/20\n",
            "141/141 - 2s - loss: 0.0803 - accuracy: 0.0071\n",
            "Epoch 14/20\n",
            "141/141 - 2s - loss: 0.0757 - accuracy: 0.0071\n",
            "Epoch 15/20\n",
            "141/141 - 2s - loss: 0.0693 - accuracy: 0.0071\n",
            "Epoch 16/20\n",
            "141/141 - 2s - loss: 0.0725 - accuracy: 0.0071\n",
            "Epoch 17/20\n",
            "141/141 - 2s - loss: 0.0569 - accuracy: 0.0071\n",
            "Epoch 18/20\n",
            "141/141 - 2s - loss: 0.0648 - accuracy: 0.0071\n",
            "Epoch 19/20\n",
            "141/141 - 2s - loss: 0.0478 - accuracy: 0.0071\n",
            "Epoch 20/20\n",
            "141/141 - 2s - loss: 0.0541 - accuracy: 0.0071\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57b2edc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.007347382605075836\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n",
            "Epoch 1/20\n",
            "141/141 - 2s - loss: 0.2598 - accuracy: 0.0071\n",
            "Epoch 2/20\n",
            "141/141 - 2s - loss: 0.2984 - accuracy: 0.0071\n",
            "Epoch 3/20\n",
            "141/141 - 2s - loss: 0.2473 - accuracy: 0.0071\n",
            "Epoch 4/20\n",
            "141/141 - 2s - loss: 0.1340 - accuracy: 0.0071\n",
            "Epoch 5/20\n",
            "141/141 - 2s - loss: 0.1441 - accuracy: 0.0071\n",
            "Epoch 6/20\n",
            "141/141 - 2s - loss: 0.1081 - accuracy: 0.0071\n",
            "Epoch 7/20\n",
            "141/141 - 2s - loss: 0.1214 - accuracy: 0.0071\n",
            "Epoch 8/20\n",
            "141/141 - 2s - loss: 0.1039 - accuracy: 0.0071\n",
            "Epoch 9/20\n",
            "141/141 - 2s - loss: 0.1034 - accuracy: 0.0071\n",
            "Epoch 10/20\n",
            "141/141 - 2s - loss: 0.1090 - accuracy: 0.0071\n",
            "Epoch 11/20\n",
            "141/141 - 2s - loss: 0.0883 - accuracy: 0.0071\n",
            "Epoch 12/20\n",
            "141/141 - 2s - loss: 0.0813 - accuracy: 0.0071\n",
            "Epoch 13/20\n",
            "141/141 - 2s - loss: 0.0775 - accuracy: 0.0071\n",
            "Epoch 14/20\n",
            "141/141 - 2s - loss: 0.0692 - accuracy: 0.0071\n",
            "Epoch 15/20\n",
            "141/141 - 2s - loss: 0.0641 - accuracy: 0.0071\n",
            "Epoch 16/20\n",
            "141/141 - 2s - loss: 0.0718 - accuracy: 0.0071\n",
            "Epoch 17/20\n",
            "141/141 - 2s - loss: 0.0669 - accuracy: 0.0071\n",
            "Epoch 18/20\n",
            "141/141 - 2s - loss: 0.0664 - accuracy: 0.0071\n",
            "Epoch 19/20\n",
            "141/141 - 2s - loss: 0.0607 - accuracy: 0.0071\n",
            "Epoch 20/20\n",
            "141/141 - 2s - loss: 0.0754 - accuracy: 0.0071\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f57a509e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test score: 0.03486395627260208\n",
            "正答率: 0.0\n",
            "save the architecture of a model\n",
            "save weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "id": "5zNautIBv0p8",
        "outputId": "2577cb70-4238-41fa-9ff0-b9379e9d17d2"
      },
      "source": [
        "df6\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>9217.440205</td>\n",
              "      <td>9687.233848</td>\n",
              "      <td>10250.288340</td>\n",
              "      <td>9001.338266</td>\n",
              "      <td>9579.601104</td>\n",
              "      <td>9327.202606</td>\n",
              "      <td>9047.851119</td>\n",
              "      <td>9495.990595</td>\n",
              "      <td>9030.733816</td>\n",
              "      <td>8634.726566</td>\n",
              "      <td>9015.936548</td>\n",
              "      <td>9317.110651</td>\n",
              "      <td>10905.356203</td>\n",
              "      <td>9232.963689</td>\n",
              "      <td>9680.494511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>NaN</td>\n",
              "      <td>9242.845979</td>\n",
              "      <td>10176.991196</td>\n",
              "      <td>9701.079247</td>\n",
              "      <td>9577.109243</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8906.441997</td>\n",
              "      <td>9141.287497</td>\n",
              "      <td>9686.739496</td>\n",
              "      <td>8674.313251</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9153.422052</td>\n",
              "      <td>9440.286586</td>\n",
              "      <td>10349.208700</td>\n",
              "      <td>8769.817842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9580.116820</td>\n",
              "      <td>9538.984362</td>\n",
              "      <td>10237.007776</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8926.938699</td>\n",
              "      <td>9368.318503</td>\n",
              "      <td>9274.214337</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9199.276333</td>\n",
              "      <td>10120.175644</td>\n",
              "      <td>10078.252373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8964.448064</td>\n",
              "      <td>10243.001767</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9154.936870</td>\n",
              "      <td>9029.502182</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10004.455394</td>\n",
              "      <td>9685.433410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9521.176189</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8703.031434</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9178.853231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            close        close  ...         close         close\n",
              "213   9000.000000  9000.000000  ...   9000.000000   9000.000000\n",
              "214   9000.000000  9000.000000  ...   9000.000000   9000.000000\n",
              "215   9040.000000  9040.000000  ...   9040.000000   9040.000000\n",
              "216   8360.000000  8360.000000  ...   8360.000000   8360.000000\n",
              "217   7870.000000  7870.000000  ...   7870.000000   7870.000000\n",
              "218   8500.000000  8500.000000  ...   8500.000000   8500.000000\n",
              "219   8410.000000  8410.000000  ...   8410.000000   8410.000000\n",
              "220   8150.000000  8150.000000  ...   8150.000000   8150.000000\n",
              "221   7820.000000  7820.000000  ...   7820.000000   7820.000000\n",
              "222   8230.000000  8230.000000  ...   8230.000000   8230.000000\n",
              "223   8420.000000  8420.000000  ...   8420.000000   8420.000000\n",
              "224   8900.000000  8900.000000  ...   8900.000000   8900.000000\n",
              "225   9600.000000  9600.000000  ...   9600.000000   9600.000000\n",
              "226   9220.000000  9220.000000  ...   9220.000000   9220.000000\n",
              "227   9270.000000  9270.000000  ...   9270.000000   9270.000000\n",
              "228   8920.000000  8920.000000  ...   8920.000000   8920.000000\n",
              "229   9220.000000  9220.000000  ...   9220.000000   9220.000000\n",
              "230   9820.000000  9820.000000  ...   9820.000000   9820.000000\n",
              "231   9350.000000  9350.000000  ...   9350.000000   9350.000000\n",
              "232   9200.000000  9200.000000  ...   9200.000000   9200.000000\n",
              "1001  9217.440205  9687.233848  ...   9232.963689   9680.494511\n",
              "1002          NaN  9242.845979  ...  10349.208700   8769.817842\n",
              "1003          NaN          NaN  ...  10120.175644  10078.252373\n",
              "1004          NaN          NaN  ...  10004.455394   9685.433410\n",
              "1005          NaN          NaN  ...           NaN   9178.853231\n",
              "\n",
              "[25 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXJceDoKuzqu",
        "outputId": "26692847-b057-4615-f024-cd57acbe02ea"
      },
      "source": [
        "f=df4[-2*n:-n]\n",
        "f.iloc[-n, :]\n",
        "df4.iloc[-n, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "close   -0.999996\n",
              "Name: 0, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "Gg9gDqUDtuss",
        "outputId": "afd3d13a-13af-4314-fedd-316d55d898b0"
      },
      "source": [
        "\n",
        "df4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>9000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>9000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>9040.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>8360.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>7870.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>8500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>8410.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>8150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>7820.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>8230.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>8420.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>8900.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>9600.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>9220.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>9270.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>8920.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>9220.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>9820.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>9350.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>9200.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.999996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.004322</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           close\n",
              "213  9000.000000\n",
              "214  9000.000000\n",
              "215  9040.000000\n",
              "216  8360.000000\n",
              "217  7870.000000\n",
              "218  8500.000000\n",
              "219  8410.000000\n",
              "220  8150.000000\n",
              "221  7820.000000\n",
              "222  8230.000000\n",
              "223  8420.000000\n",
              "224  8900.000000\n",
              "225  9600.000000\n",
              "226  9220.000000\n",
              "227  9270.000000\n",
              "228  8920.000000\n",
              "229  9220.000000\n",
              "230  9820.000000\n",
              "231  9350.000000\n",
              "232  9200.000000\n",
              "0      -0.999996\n",
              "1      -0.004322"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "5kDsDqIarmpQ",
        "outputId": "62aaba42-8837-426f-be17-5bc90b2eb1f9"
      },
      "source": [
        "df4[\"close\"][-n:]=df4[\"close\"][-2*n:-n]*df4[\"close\"][-n:]\n",
        "df4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-219-51e3c2407268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"close\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"close\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdf4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"close\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'value'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3VOBv4mlrsw",
        "outputId": "cff200b5-317a-4150-8a97-a86202ef3e2d"
      },
      "source": [
        "df4[\"close\"][-n:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0   -0.045676\n",
              "1   -0.057127\n",
              "Name: close, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "zNjFwNHubdlr",
        "outputId": "2bb15978-8f25-45eb-cc9c-f74cc1575ca4"
      },
      "source": [
        "df4=pd.concat([df3,df2],axis=0)\n",
        "df5=pd.DataFrame()\n",
        "df5=pd.concat([df5,df4],axis=1)\n",
        "df5=pd.concat([df5,df3],axis=1)\n",
        "df5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>close</th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.819455</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.495852</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>9000.000000</td>\n",
              "      <td>9000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>9040.000000</td>\n",
              "      <td>9040.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>8360.000000</td>\n",
              "      <td>8360.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>7870.000000</td>\n",
              "      <td>7870.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>8500.000000</td>\n",
              "      <td>8500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>8410.000000</td>\n",
              "      <td>8410.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>8150.000000</td>\n",
              "      <td>8150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>7820.000000</td>\n",
              "      <td>7820.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>8230.000000</td>\n",
              "      <td>8230.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>8420.000000</td>\n",
              "      <td>8420.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>8900.000000</td>\n",
              "      <td>8900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>9600.000000</td>\n",
              "      <td>9600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>9270.000000</td>\n",
              "      <td>9270.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>8920.000000</td>\n",
              "      <td>8920.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>9220.000000</td>\n",
              "      <td>9220.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>9820.000000</td>\n",
              "      <td>9820.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>9350.000000</td>\n",
              "      <td>9350.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>9200.000000</td>\n",
              "      <td>9200.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           close   close\n",
              "0       7.819455     NaN\n",
              "1       7.495852     NaN\n",
              "213  9000.000000  9000.0\n",
              "214  9000.000000  9000.0\n",
              "215  9040.000000  9040.0\n",
              "216  8360.000000  8360.0\n",
              "217  7870.000000  7870.0\n",
              "218  8500.000000  8500.0\n",
              "219  8410.000000  8410.0\n",
              "220  8150.000000  8150.0\n",
              "221  7820.000000  7820.0\n",
              "222  8230.000000  8230.0\n",
              "223  8420.000000  8420.0\n",
              "224  8900.000000  8900.0\n",
              "225  9600.000000  9600.0\n",
              "226  9220.000000  9220.0\n",
              "227  9270.000000  9270.0\n",
              "228  8920.000000  8920.0\n",
              "229  9220.000000  9220.0\n",
              "230  9820.000000  9820.0\n",
              "231  9350.000000  9350.0\n",
              "232  9200.000000  9200.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "AHokogkqdQI5",
        "outputId": "637e1894-af13-4a7c-c963-8e1e205673fe"
      },
      "source": [
        "model.predict(predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-161-293ca3ca03a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1577\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 971\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    972\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'function'>, <class 'NoneType'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "To20qWLGJVde",
        "outputId": "d9b5b8d2-e17c-406b-e572-e5eb0b4d4b36"
      },
      "source": [
        "code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4478'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2mQ28sKeQwX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "5a6309d8-b238-4633-c47e-bd6f2a7ba593"
      },
      "source": [
        " import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(df4.index, df4['3994'], label='close', color='blue')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efbd04d5ef0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0OQeechhKZT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}